{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1bu9xXsudva3rRDuqwC27-tKKyK2321QO",
      "authorship_tag": "ABX9TyPBTTOXmcRXphEJkDURpqF1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nandikathapa4-gif/nandika-thapa-projects/blob/main/FinTech_Survey_Analysis_Nepal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Impact of FinTech on Traditional Banking in Nepal**"
      ],
      "metadata": {
        "id": "a1dKrH58GJgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introduction**                          Primary survey with 110+ responses on adoption, satisfaction, and challenges."
      ],
      "metadata": {
        "id": "2ft_6x2CGOS6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "lxsW3hQeFIDn",
        "outputId": "e06e73ce-03eb-48ce-e883-659481bed6c6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/GITHUB/fintech_responses.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2570690141.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/GITHUB/fintech_responses.csv'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Load the CSV file from Google Drive/GITHUB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/GITHUB/fintech_responses.csv'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv('/content/drive/My Drive/GITHUB/fintech_responses.csv')  # Load the CSV file from Google Drive/GITHUB\n",
        "display(df.head())\n",
        "\n",
        "# Q7: Branch visits reduction\n",
        "plt.figure(figsize=(8,5))\n",
        "df['Q7. Has the use of FinTech services reduced your visits to physical bank branches?'].value_counts().plot(kind='bar', color='teal')\n",
        "plt.title('Impact on Physical Bank Visits')\n",
        "plt.ylabel('Responses')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()\n",
        "\n",
        "# Q8: Satisfaction\n",
        "plt.figure(figsize=(6,4))\n",
        "df['Q8. How satisfied are you with FinTech services compared to traditional banking?'].astype(int).value_counts().sort_index().plot(kind='bar', color='green')\n",
        "plt.title('Satisfaction Level (1-5)')\n",
        "plt.xlabel('Score')\n",
        "plt.show()\n",
        "\n",
        "# Q9: Adoption reasons (multi-select split)\n",
        "reasons = df['Q9. What are the main reasons you use FinTech services over traditional banking?'].str.split(', ').explode().str.strip()\n",
        "top_reasons = reasons.value_counts().head(10)\n",
        "top_reasons.plot(kind='barh', color='skyblue')\n",
        "plt.title('Top Adoption Drivers')\n",
        "plt.xlabel('Responses')\n",
        "plt.show()\n",
        "\n",
        "# Q13: Future outlook\n",
        "plt.figure(figsize=(6,6))\n",
        "df['Q13. Do you think FinTech services will replace traditional banking in Nepal in the next 10 years?'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
        "plt.title('Will FinTech Replace Traditional Banking?')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64832792",
        "outputId": "88ca9596-b1d1-440f-a2ef-a86b2607b385"
      },
      "source": [
        "import os\n",
        "\n",
        "# List contents of the specified directory\n",
        "drive_path = '/content/drive/My Drive/'\n",
        "if os.path.exists(drive_path):\n",
        "    print(f\"Contents of '{drive_path}':\")\n",
        "    for item in os.listdir(drive_path):\n",
        "        print(item)\n",
        "else:\n",
        "    print(f\"Directory '{drive_path}' does not exist or is not mounted.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory '/content/drive/My Drive/' does not exist or is not mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d72a424"
      },
      "source": [
        "!ls -F '/content/drive/My Drive/colab notebooks/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15d8269d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d898b0ff"
      },
      "source": [
        "!ls -F"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eee9cb8"
      },
      "source": [
        "# Task\n",
        "Prepare data for location-based analysis of FinTech adoption reasons by creating a new DataFrame that links each FinTech adoption reason to its corresponding location and then grouping and counting the occurrences of each reason within each city. After that, filter this data to focus on the top overall adoption reasons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2210b753"
      },
      "source": [
        "## Prepare Data for Location-Based Reason Analysis\n",
        "\n",
        "### Subtask:\n",
        "Transform the 'Q9' multi-select column into a format suitable for analysis by location. This will involve exploding the comma-separated reasons and then grouping the data by 'Q2. Location (City)' to count the occurrences of each FinTech adoption reason within each city.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "983ada67"
      },
      "source": [
        "**Reasoning**:\n",
        "To prepare the data for location-based reason analysis, I will select the relevant columns, explode the multi-select reasons, count their occurrences by city, reset the index, and rename the columns as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0d001de9"
      },
      "source": [
        "location_reasons_df = df[['Q2. Location (City)', 'Q9. What are the main reasons you use FinTech services over traditional banking?']].copy()\n",
        "\n",
        "location_reasons_df['Q9. What are the main reasons you use FinTech services over traditional banking?'] = \\\n",
        "    location_reasons_df['Q9. What are the main reasons you use FinTech services over traditional banking?'].str.split(', ')\n",
        "\n",
        "location_reasons_df = location_reasons_df.explode('Q9. What are the main reasons you use FinTech services over traditional banking?')\n",
        "location_reasons_df['Q9. What are the main reasons you use FinTech services over traditional banking?'] = \\\n",
        "    location_reasons_df['Q9. What are the main reasons you use FinTech services over traditional banking?'].str.strip()\n",
        "\n",
        "location_reasons_df = location_reasons_df.groupby(['Q2. Location (City)', 'Q9. What are the main reasons you use FinTech services over traditional banking?']).size().reset_index(name='Count')\n",
        "\n",
        "location_reasons_df.rename(columns={'Q9. What are the main reasons you use FinTech services over traditional banking?': 'Reason', 'Q2. Location (City)': 'Location'}, inplace=True)\n",
        "\n",
        "display(location_reasons_df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9a48c7b2"
      },
      "source": [
        "**Reasoning**:\n",
        "The next step is to filter the `location_reasons_df` to include only the top overall adoption reasons. I will use the `top_reasons` Series already computed in the previous steps to get these reasons and then filter the DataFrame accordingly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69101e73"
      },
      "source": [
        "top_reasons_list = top_reasons.index.tolist()\n",
        "filtered_location_reasons_df = location_reasons_df[location_reasons_df['Reason'].isin(top_reasons_list)]\n",
        "\n",
        "display(filtered_location_reasons_df.head())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ceb7f52"
      },
      "source": [
        "## Generate High-Quality Visualizations of Adoption Reasons by Location\n",
        "\n",
        "### Subtask:\n",
        "Create professional bar charts to display the distribution of key FinTech adoption reasons across different locations, ensuring high visual quality suitable for a master's degree portfolio.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67a96f92"
      },
      "source": [
        "**Reasoning**:\n",
        "To visualize the distribution of FinTech adoption reasons across different locations, I will iterate through each unique location in the `filtered_location_reasons_df` and create a bar chart for the top reasons in that specific location.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64b9daba"
      },
      "source": [
        "unique_locations = filtered_location_reasons_df['Location'].unique()\n",
        "\n",
        "for location in unique_locations:\n",
        "    location_data = filtered_location_reasons_df[filtered_location_reasons_df['Location'] == location]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x='Reason', y='Count', data=location_data, palette='viridis')\n",
        "    plt.title(f'Top FinTech Adoption Reasons in {location}', fontsize=16)\n",
        "    plt.xlabel('FinTech Adoption Reason', fontsize=12)\n",
        "    plt.ylabel('Number of Responses', fontsize=12)\n",
        "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
        "    plt.yticks(fontsize=10)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "275156a1"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code generated a `FutureWarning` regarding the `palette` parameter in `sns.barplot`. To address this and follow the suggested best practice, I will assign the `Reason` column to the `hue` parameter and set `legend=False` in the `sns.barplot` function call.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34d19061"
      },
      "source": [
        "unique_locations = filtered_location_reasons_df['Location'].unique()\n",
        "\n",
        "for location in unique_locations:\n",
        "    location_data = filtered_location_reasons_df[filtered_location_reasons_df['Location'] == location]\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x='Reason', y='Count', hue='Reason', data=location_data, palette='viridis', legend=False)\n",
        "    plt.title(f'Top FinTech Adoption Reasons in {location}', fontsize=16)\n",
        "    plt.xlabel('FinTech Adoption Reason', fontsize=12)\n",
        "    plt.ylabel('Number of Responses', fontsize=12)\n",
        "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
        "    plt.yticks(fontsize=10)\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}